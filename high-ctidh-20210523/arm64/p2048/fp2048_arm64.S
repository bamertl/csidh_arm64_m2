/* DO NOT EDIT! generated by autogen */

#include "../../uintbig_namespace.h"
#include "../../fp_namespace.h"
.extern uintbig_mul3_64
.extern uintbig_mul3_64_full
.extern uintbig_add3
.extern uintbig_sub3


.set pbits, 2047 
.set pbytes, 256 
.set plimbs, 32 

.global fp_0
fp_0: 
	.zero 256

	/* 2^2048 mod p */
.global fp_1
fp_1: 
    .quad 0x994d7dbe41f62437, 0x6aaf42d975b174b6, 0x3f037f5ba7c4a965, 0x5ccaed897fd53a00
    .quad 0xd2973e879030fb33, 0x08c3a6b0fcf19681, 0x33301470a926eefd, 0x33e715b0a4a9b9e9
    .quad 0x8737cc516cf9ace5, 0xf5464238325eccd4, 0x393cd9de4f760e82, 0x059880446fb9a315
    .quad 0x8b19e3b333b22e4a, 0x65ac4ae7830805fa, 0xd71b975ca89c8fcd, 0x37314ebe2cf1f23b
    .quad 0x565f6b8c9e61cfb9, 0x87712cf7de06573f, 0x6d8736050fb35ad2, 0xe3efa60224957edb
    .quad 0x444a4fc8b855012d, 0xac7f2394665a0905, 0xcff83c43b74af366, 0x167df91c271503fd
    .quad 0xd70947c16f7fc287, 0x65069931a3a5d5b7, 0xf713ec84671a7fce, 0x6c8a0b9c659af905
    .quad 0x6600692af35042c7, 0x17670145e45b2b04, 0x38030a4d47b3b374, 0x355309fecf901ad2

	/* 2^2049 mod p */
.global fp_2
fp_2: 
    .quad 0xbb0a256699e8ff2b, 0xf8ee46a6129e1054, 0xe85d7e8087758b41, 0xd8842a40d4f18755
    .quad 0x40b63c91a5c79f77, 0x69c884f24e33b484, 0x221ada5c355ad84e, 0x23c5dd46d58c0720
    .quad 0xe62cdcbdfe46936c, 0x91a3efd87587ddef, 0xdae351b164137731, 0xb7b92b4a5a067c86
    .quad 0x99e7134ccdf516ac, 0x4292041c31bd6348, 0xa095b682dec2a4df, 0xd61db7bbbe348a8b
    .quad 0xc98950481c398f5a, 0x915d68ed060ecb93, 0xaa3b7e0bcf4d2940, 0xbe84835a555cd2aa
    .quad 0xf4ad64d458c65815, 0x927dfdaf997cbfb6, 0x3a988c9e010437ef, 0xdf25efec5b310950
    .quad 0xf5c05218aed4c5e5, 0x9664bac92882f2ac, 0x95d927df9b3dd4e1, 0xfd421b1797beefb8
    .quad 0xee00f56437bb467b, 0xe145ada314d4b9b4, 0xd8071809a74df80e, 0x271717528efae93f

	/* (2^2048)^2 mod p */
.r_squared_mod_p: /* (2^2048)^2 mod p */
    .quad 0x6e940162ecb00f8c, 0x24c744036302b024, 0xc892a6ce3f16637b, 0x37733ccc6ac611b0
    .quad 0xe5361a2cfb50bcf7, 0xe06f5b5f3f269a1f, 0x67d1d25e92181152, 0xab5a12bd6902fcfc
    .quad 0x82c060ea7daaebd0, 0x22029cf3781c2b9e, 0x0cfdf6fb51053d83, 0xd0af69954ce04fb3
    .quad 0x015a5254e7ef0c6d, 0x834839d5541a461a, 0x6768d972de4e269a, 0x71a06dcb2a0a7a7f
    .quad 0x0e11b7d51a8ef22f, 0x9d655dcdeb3d4934, 0x28dfab822c934ea8, 0x60a2ba69a0862d99
    .quad 0xf1286b89b68ee540, 0xb16c9ae335599258, 0x4a30cb66a64be15f, 0xd021ee65d62b98ce
    .quad 0xae101149f5e60533, 0x2ad923e56bee4dc3, 0x5ccb61e26b6f93b5, 0xa4ee09d81cc595af
    .quad 0xdc3497d89520ca1f, 0x2ab20fe509190878, 0xcb8fab09772c236e, 0x2dc5652f8085f6a5


.global uint_big_p
uint_big_p: 
    .quad 0x7790d615ea034943, 0xdc703f0cd8c4d918, 0x95a98036c813c788, 0xe111b0d22ab8ecaa
    .quad 0x6478407d7a9a56ee, 0xa7bec86fabaf787f, 0x44454e851cf305ab, 0x44084e1a73c76cb2
    .quad 0x2842bbe4dbacc65e, 0x58e89497ef35bbb9, 0x9796620b3ad8a5d4, 0x5377d53e856cc9a3
    .quad 0x7c4cb419996f45e7, 0x88c691b2d452a8ac, 0x0da1783672767abb, 0x9844e5c09baf59ec
    .quad 0xe33586d1208a1017, 0x7d84f102b5fde2ea, 0x30d2edfe50198c64, 0x095ac8a9f3ce2b0c
    .quad 0x93e73abd17e3aa46, 0xc680497933375253, 0x6557ebe96d91aedd, 0x4dd6024bf2f8feab
    .quad 0xb8523d6a302abf28, 0x33a8779a1ec8b8c2, 0x584eb12932f72abb, 0xdbd1fc2133770253
    .quad 0xddffdcf1aee53f12, 0x4d8854e8b3e19c53, 0x97fefc90e8196ed9, 0x438efcab10254c64

.data
.global fp_mulsq_count
fp_mulsq_count: 
	.quad 0
.global fp_sq_count
fp_sq_count: 
	.quad 0
.global fp_addsub_count
fp_addsub_count: 
	.quad 0

.text
.align 4

	/* [x1] = [x0]  x0 is being copied to x1 */
.global fp_copy
fp_copy: 
	ldp x3, x4, [x0, #0]
	ldp x5, x6, [x0, #16]
	ldp x7, x8, [x0, #32]
	ldp x9, x10, [x0, #48]
	stp x3, x4, [x1, #0]
	stp x5, x6, [x1, #16]
	stp x7, x8, [x1, #32]
	stp x9, x10, [x1, #48]
	ldp x3, x4, [x0, #64]
	ldp x5, x6, [x0, #80]
	ldp x7, x8, [x0, #96]
	ldp x9, x10, [x0, #112]
	stp x3, x4, [x1, #64]
	stp x5, x6, [x1, #80]
	stp x7, x8, [x1, #96]
	stp x9, x10, [x1, #112]
	ldp x3, x4, [x0, #128]
	ldp x5, x6, [x0, #144]
	ldp x7, x8, [x0, #160]
	ldp x9, x10, [x0, #176]
	stp x3, x4, [x1, #128]
	stp x5, x6, [x1, #144]
	stp x7, x8, [x1, #160]
	stp x9, x10, [x1, #176]
	ldp x3, x4, [x0, #192]
	ldp x5, x6, [x0, #208]
	ldp x7, x8, [x0, #224]
	ldp x9, x10, [x0, #240]
	stp x3, x4, [x1, #192]
	stp x5, x6, [x1, #208]
	stp x7, x8, [x1, #224]
	stp x9, x10, [x1, #240]
	ret

	/* A[x0] = B[x1] if d[x2], we make it time-constant */
.global fp_cmov
fp_cmov: 
	/* (AxorB)^d xor A = A */
	/* A xor 0 = A */
	/*  d-1 = 1111 or 0000 that why it is like this */
	/* A xor B and 1 xor B = A */
	/* A xor B and 0 xor B = B */
	subs x15, x2, #1
	/* Batch 0 */
	ldp x3, x4, [x0, #0]
	ldp x7, x8, [x1, #0]
	ldp x5, x6, [x0, #16]
	ldp x9, x10, [x1, #16]
	eor x11, x3, x7 // A xor B 
	eor x12, x4, x8
	eor x13, x5, x9
	eor x14, x6, x10

	and x11, x11, x15 // A xor B and d 
	and x12, x12, x15
	and x13, x13, x15
	and x14, x14, x15

	eor x11, x11, x7 // A xor B and d xor B 
	eor x12, x12, x8
	eor x13, x13, x9
	eor x14, x14, x10

	stp x11, x12, [x0, #0]
	stp x13, x14, [x0, #16]
	/* Batch 1 */
	ldp x3, x4, [x0, #32]
	ldp x7, x8, [x1, #32]
	ldp x5, x6, [x0, #48]
	ldp x9, x10, [x1, #48]
	eor x11, x3, x7 // A xor B 
	eor x12, x4, x8
	eor x13, x5, x9
	eor x14, x6, x10

	and x11, x11, x15 // A xor B and d 
	and x12, x12, x15
	and x13, x13, x15
	and x14, x14, x15

	eor x11, x11, x7 // A xor B and d xor B 
	eor x12, x12, x8
	eor x13, x13, x9
	eor x14, x14, x10

	stp x11, x12, [x0, #32]
	stp x13, x14, [x0, #48]
	/* Batch 2 */
	ldp x3, x4, [x0, #64]
	ldp x7, x8, [x1, #64]
	ldp x5, x6, [x0, #80]
	ldp x9, x10, [x1, #80]
	eor x11, x3, x7 // A xor B 
	eor x12, x4, x8
	eor x13, x5, x9
	eor x14, x6, x10

	and x11, x11, x15 // A xor B and d 
	and x12, x12, x15
	and x13, x13, x15
	and x14, x14, x15

	eor x11, x11, x7 // A xor B and d xor B 
	eor x12, x12, x8
	eor x13, x13, x9
	eor x14, x14, x10

	stp x11, x12, [x0, #64]
	stp x13, x14, [x0, #80]
	/* Batch 3 */
	ldp x3, x4, [x0, #96]
	ldp x7, x8, [x1, #96]
	ldp x5, x6, [x0, #112]
	ldp x9, x10, [x1, #112]
	eor x11, x3, x7 // A xor B 
	eor x12, x4, x8
	eor x13, x5, x9
	eor x14, x6, x10

	and x11, x11, x15 // A xor B and d 
	and x12, x12, x15
	and x13, x13, x15
	and x14, x14, x15

	eor x11, x11, x7 // A xor B and d xor B 
	eor x12, x12, x8
	eor x13, x13, x9
	eor x14, x14, x10

	stp x11, x12, [x0, #96]
	stp x13, x14, [x0, #112]
	/* Batch 4 */
	ldp x3, x4, [x0, #128]
	ldp x7, x8, [x1, #128]
	ldp x5, x6, [x0, #144]
	ldp x9, x10, [x1, #144]
	eor x11, x3, x7 // A xor B 
	eor x12, x4, x8
	eor x13, x5, x9
	eor x14, x6, x10

	and x11, x11, x15 // A xor B and d 
	and x12, x12, x15
	and x13, x13, x15
	and x14, x14, x15

	eor x11, x11, x7 // A xor B and d xor B 
	eor x12, x12, x8
	eor x13, x13, x9
	eor x14, x14, x10

	stp x11, x12, [x0, #128]
	stp x13, x14, [x0, #144]
	/* Batch 5 */
	ldp x3, x4, [x0, #160]
	ldp x7, x8, [x1, #160]
	ldp x5, x6, [x0, #176]
	ldp x9, x10, [x1, #176]
	eor x11, x3, x7 // A xor B 
	eor x12, x4, x8
	eor x13, x5, x9
	eor x14, x6, x10

	and x11, x11, x15 // A xor B and d 
	and x12, x12, x15
	and x13, x13, x15
	and x14, x14, x15

	eor x11, x11, x7 // A xor B and d xor B 
	eor x12, x12, x8
	eor x13, x13, x9
	eor x14, x14, x10

	stp x11, x12, [x0, #160]
	stp x13, x14, [x0, #176]
	/* Batch 6 */
	ldp x3, x4, [x0, #192]
	ldp x7, x8, [x1, #192]
	ldp x5, x6, [x0, #208]
	ldp x9, x10, [x1, #208]
	eor x11, x3, x7 // A xor B 
	eor x12, x4, x8
	eor x13, x5, x9
	eor x14, x6, x10

	and x11, x11, x15 // A xor B and d 
	and x12, x12, x15
	and x13, x13, x15
	and x14, x14, x15

	eor x11, x11, x7 // A xor B and d xor B 
	eor x12, x12, x8
	eor x13, x13, x9
	eor x14, x14, x10

	stp x11, x12, [x0, #192]
	stp x13, x14, [x0, #208]
	/* Batch 7 */
	ldp x3, x4, [x0, #224]
	ldp x7, x8, [x1, #224]
	ldp x5, x6, [x0, #240]
	ldp x9, x10, [x1, #240]
	eor x11, x3, x7 // A xor B 
	eor x12, x4, x8
	eor x13, x5, x9
	eor x14, x6, x10

	and x11, x11, x15 // A xor B and d 
	and x12, x12, x15
	and x13, x13, x15
	and x14, x14, x15

	eor x11, x11, x7 // A xor B and d xor B 
	eor x12, x12, x8
	eor x13, x13, x9
	eor x14, x14, x10

	stp x11, x12, [x0, #224]
	stp x13, x14, [x0, #240]
	ret 

	/* A[x0] <-> B[x1] if d[x2], we make it time-constant */
.global fp_cswap
fp_cswap: 
	subs x15, x2, #1
	/* Batch 0 */
	ldp x3, x4, [x0, #0]
	ldp x7, x8, [x1, #0]
	ldp x5, x6, [x0, #16]
	ldp x9, x10, [x1, #16]

	eor x11, x3, x7 // A xor B 
	eor x12, x4, x8
	eor x13, x5, x9
	eor x14, x6, x10

	and x11, x11, x15 // A xor B and d 
	and x12, x12, x15
	and x13, x13, x15
	and x14, x14, x15

	eor x7, x11, x7 // A xor B and d xor B for A 
	eor x8, x12, x8
	eor x9, x13, x9
	eor x10, x14, x10
	stp x7, x8, [x0, #0]
	stp x9, x10, [x0, #16]

	eor x3, x11, x3 // A xor B and d xor A for B 
	eor x4, x12, x4
	eor x5, x13, x5
	eor x6, x14, x6
	stp x3, x4, [x1, #0]
	stp x5, x6, [x1, #16]
	/* Batch 1 */
	ldp x3, x4, [x0, #32]
	ldp x7, x8, [x1, #32]
	ldp x5, x6, [x0, #48]
	ldp x9, x10, [x1, #48]

	eor x11, x3, x7 // A xor B 
	eor x12, x4, x8
	eor x13, x5, x9
	eor x14, x6, x10

	and x11, x11, x15 // A xor B and d 
	and x12, x12, x15
	and x13, x13, x15
	and x14, x14, x15

	eor x7, x11, x7 // A xor B and d xor B for A 
	eor x8, x12, x8
	eor x9, x13, x9
	eor x10, x14, x10
	stp x7, x8, [x0, #32]
	stp x9, x10, [x0, #48]

	eor x3, x11, x3 // A xor B and d xor A for B 
	eor x4, x12, x4
	eor x5, x13, x5
	eor x6, x14, x6
	stp x3, x4, [x1, #32]
	stp x5, x6, [x1, #48]
	/* Batch 2 */
	ldp x3, x4, [x0, #64]
	ldp x7, x8, [x1, #64]
	ldp x5, x6, [x0, #80]
	ldp x9, x10, [x1, #80]

	eor x11, x3, x7 // A xor B 
	eor x12, x4, x8
	eor x13, x5, x9
	eor x14, x6, x10

	and x11, x11, x15 // A xor B and d 
	and x12, x12, x15
	and x13, x13, x15
	and x14, x14, x15

	eor x7, x11, x7 // A xor B and d xor B for A 
	eor x8, x12, x8
	eor x9, x13, x9
	eor x10, x14, x10
	stp x7, x8, [x0, #64]
	stp x9, x10, [x0, #80]

	eor x3, x11, x3 // A xor B and d xor A for B 
	eor x4, x12, x4
	eor x5, x13, x5
	eor x6, x14, x6
	stp x3, x4, [x1, #64]
	stp x5, x6, [x1, #80]
	/* Batch 3 */
	ldp x3, x4, [x0, #96]
	ldp x7, x8, [x1, #96]
	ldp x5, x6, [x0, #112]
	ldp x9, x10, [x1, #112]

	eor x11, x3, x7 // A xor B 
	eor x12, x4, x8
	eor x13, x5, x9
	eor x14, x6, x10

	and x11, x11, x15 // A xor B and d 
	and x12, x12, x15
	and x13, x13, x15
	and x14, x14, x15

	eor x7, x11, x7 // A xor B and d xor B for A 
	eor x8, x12, x8
	eor x9, x13, x9
	eor x10, x14, x10
	stp x7, x8, [x0, #96]
	stp x9, x10, [x0, #112]

	eor x3, x11, x3 // A xor B and d xor A for B 
	eor x4, x12, x4
	eor x5, x13, x5
	eor x6, x14, x6
	stp x3, x4, [x1, #96]
	stp x5, x6, [x1, #112]
	/* Batch 4 */
	ldp x3, x4, [x0, #128]
	ldp x7, x8, [x1, #128]
	ldp x5, x6, [x0, #144]
	ldp x9, x10, [x1, #144]

	eor x11, x3, x7 // A xor B 
	eor x12, x4, x8
	eor x13, x5, x9
	eor x14, x6, x10

	and x11, x11, x15 // A xor B and d 
	and x12, x12, x15
	and x13, x13, x15
	and x14, x14, x15

	eor x7, x11, x7 // A xor B and d xor B for A 
	eor x8, x12, x8
	eor x9, x13, x9
	eor x10, x14, x10
	stp x7, x8, [x0, #128]
	stp x9, x10, [x0, #144]

	eor x3, x11, x3 // A xor B and d xor A for B 
	eor x4, x12, x4
	eor x5, x13, x5
	eor x6, x14, x6
	stp x3, x4, [x1, #128]
	stp x5, x6, [x1, #144]
	/* Batch 5 */
	ldp x3, x4, [x0, #160]
	ldp x7, x8, [x1, #160]
	ldp x5, x6, [x0, #176]
	ldp x9, x10, [x1, #176]

	eor x11, x3, x7 // A xor B 
	eor x12, x4, x8
	eor x13, x5, x9
	eor x14, x6, x10

	and x11, x11, x15 // A xor B and d 
	and x12, x12, x15
	and x13, x13, x15
	and x14, x14, x15

	eor x7, x11, x7 // A xor B and d xor B for A 
	eor x8, x12, x8
	eor x9, x13, x9
	eor x10, x14, x10
	stp x7, x8, [x0, #160]
	stp x9, x10, [x0, #176]

	eor x3, x11, x3 // A xor B and d xor A for B 
	eor x4, x12, x4
	eor x5, x13, x5
	eor x6, x14, x6
	stp x3, x4, [x1, #160]
	stp x5, x6, [x1, #176]
	/* Batch 6 */
	ldp x3, x4, [x0, #192]
	ldp x7, x8, [x1, #192]
	ldp x5, x6, [x0, #208]
	ldp x9, x10, [x1, #208]

	eor x11, x3, x7 // A xor B 
	eor x12, x4, x8
	eor x13, x5, x9
	eor x14, x6, x10

	and x11, x11, x15 // A xor B and d 
	and x12, x12, x15
	and x13, x13, x15
	and x14, x14, x15

	eor x7, x11, x7 // A xor B and d xor B for A 
	eor x8, x12, x8
	eor x9, x13, x9
	eor x10, x14, x10
	stp x7, x8, [x0, #192]
	stp x9, x10, [x0, #208]

	eor x3, x11, x3 // A xor B and d xor A for B 
	eor x4, x12, x4
	eor x5, x13, x5
	eor x6, x14, x6
	stp x3, x4, [x1, #192]
	stp x5, x6, [x1, #208]
	/* Batch 7 */
	ldp x3, x4, [x0, #224]
	ldp x7, x8, [x1, #224]
	ldp x5, x6, [x0, #240]
	ldp x9, x10, [x1, #240]

	eor x11, x3, x7 // A xor B 
	eor x12, x4, x8
	eor x13, x5, x9
	eor x14, x6, x10

	and x11, x11, x15 // A xor B and d 
	and x12, x12, x15
	and x13, x13, x15
	and x14, x14, x15

	eor x7, x11, x7 // A xor B and d xor B for A 
	eor x8, x12, x8
	eor x9, x13, x9
	eor x10, x14, x10
	stp x7, x8, [x0, #224]
	stp x9, x10, [x0, #240]

	eor x3, x11, x3 // A xor B and d xor A for B 
	eor x4, x12, x4
	eor x5, x13, x5
	eor x6, x14, x6
	stp x3, x4, [x1, #224]
	stp x5, x6, [x1, #240]
	ret 

	/* A[x0] = A[x0] + B[x1] */
.global fp_add2
fp_add2: 
	mov x2, x0  
	/* A[x0] = B[x1] + C[x2] */
.global fp_add3
fp_add3: 
	/* Increment add/sub counter */
	adrp x3, fp_addsub_count@PAGE
	add x3, x3, fp_addsub_count@PAGEOFF
	ldr x4, [x3]
	add x4, x4, #1
	str x4, [x3]

	sub sp, sp, #32
	stp x21, x22, [sp, #0]
	stp x23, lr, [sp, #16]
	mov x21, x0  
	adrp x23, uintbig_p@PAGE
	add x23, x23, uintbig_p@PAGEOFF
	bl uintbig_add3 // x0 is now the carry 
	mov x22, x0  
	ldp x3, x4, [x21, #0]  
	ldp x7, x8, [x23, #0]  
	ldp x5, x6, [x21, #16]  
	ldp x9, x10, [x23, #16]  
	subs x11, x3, x7  
	sbcs x12, x4, x8  
	sbcs x13, x5, x9  
	sbcs x14, x6, x10  
	stp x11, x12, [x21, #0]  
	stp x13, x14, [x21, #16]  
	ldp x3, x4, [x21, #32]  
	ldp x7, x8, [x23, #32]  
	ldp x5, x6, [x21, #48]  
	ldp x9, x10, [x23, #48]  
	sbcs x11, x3, x7  
	sbcs x12, x4, x8  
	sbcs x13, x5, x9  
	sbcs x14, x6, x10  
	stp x11, x12, [x21, #32]  
	stp x13, x14, [x21, #48]  
	ldp x3, x4, [x21, #64]  
	ldp x7, x8, [x23, #64]  
	ldp x5, x6, [x21, #80]  
	ldp x9, x10, [x23, #80]  
	sbcs x11, x3, x7  
	sbcs x12, x4, x8  
	sbcs x13, x5, x9  
	sbcs x14, x6, x10  
	stp x11, x12, [x21, #64]  
	stp x13, x14, [x21, #80]  
	ldp x3, x4, [x21, #96]  
	ldp x7, x8, [x23, #96]  
	ldp x5, x6, [x21, #112]  
	ldp x9, x10, [x23, #112]  
	sbcs x11, x3, x7  
	sbcs x12, x4, x8  
	sbcs x13, x5, x9  
	sbcs x14, x6, x10  
	stp x11, x12, [x21, #96]  
	stp x13, x14, [x21, #112]  
	ldp x3, x4, [x21, #128]  
	ldp x7, x8, [x23, #128]  
	ldp x5, x6, [x21, #144]  
	ldp x9, x10, [x23, #144]  
	sbcs x11, x3, x7  
	sbcs x12, x4, x8  
	sbcs x13, x5, x9  
	sbcs x14, x6, x10  
	stp x11, x12, [x21, #128]  
	stp x13, x14, [x21, #144]  
	ldp x3, x4, [x21, #160]  
	ldp x7, x8, [x23, #160]  
	ldp x5, x6, [x21, #176]  
	ldp x9, x10, [x23, #176]  
	sbcs x11, x3, x7  
	sbcs x12, x4, x8  
	sbcs x13, x5, x9  
	sbcs x14, x6, x10  
	stp x11, x12, [x21, #160]  
	stp x13, x14, [x21, #176]  
	ldp x3, x4, [x21, #192]  
	ldp x7, x8, [x23, #192]  
	ldp x5, x6, [x21, #208]  
	ldp x9, x10, [x23, #208]  
	sbcs x11, x3, x7  
	sbcs x12, x4, x8  
	sbcs x13, x5, x9  
	sbcs x14, x6, x10  
	stp x11, x12, [x21, #192]  
	stp x13, x14, [x21, #208]  
	ldp x3, x4, [x21, #224]  
	ldp x7, x8, [x23, #224]  
	ldp x5, x6, [x21, #240]  
	ldp x9, x10, [x23, #240]  
	sbcs x11, x3, x7  
	sbcs x12, x4, x8  
	sbcs x13, x5, x9  
	sbcs x14, x6, x10  
	stp x11, x12, [x21, #224]  
	stp x13, x14, [x21, #240]  
	sbcs x22, x22, xzr  
	sbcs x22, xzr, xzr  
	/* carry again into x22 */
	ldp x3, x4, [x21, #0]  
	ldp x7, x8, [x23, #0]  
	ldp x5, x6, [x21, #16]  
	ldp x9, x10, [x23, #16]  
	and x7, x7, x22  
	and x8, x8, x22  
	and x9, x9, x22  
	and x10, x10, x22  
	adds x11, x3, x7  
	adcs x12, x4, x8  
	adcs x13, x5, x9  
	adcs x14, x6, x10  
	stp x11, x12, [x21, #0]  
	stp x13, x14, [x21, #16]  
	ldp x3, x4, [x21, #32]  
	ldp x7, x8, [x23, #32]  
	ldp x5, x6, [x21, #48]  
	ldp x9, x10, [x23, #48]  
	and x7, x7, x22  
	and x8, x8, x22  
	and x9, x9, x22  
	and x10, x10, x22  
	adcs x11, x3, x7  
	adcs x12, x4, x8  
	adcs x13, x5, x9  
	adcs x14, x6, x10  
	stp x11, x12, [x21, #32]  
	stp x13, x14, [x21, #48]  
	ldp x3, x4, [x21, #64]  
	ldp x7, x8, [x23, #64]  
	ldp x5, x6, [x21, #80]  
	ldp x9, x10, [x23, #80]  
	and x7, x7, x22  
	and x8, x8, x22  
	and x9, x9, x22  
	and x10, x10, x22  
	adcs x11, x3, x7  
	adcs x12, x4, x8  
	adcs x13, x5, x9  
	adcs x14, x6, x10  
	stp x11, x12, [x21, #64]  
	stp x13, x14, [x21, #80]  
	ldp x3, x4, [x21, #96]  
	ldp x7, x8, [x23, #96]  
	ldp x5, x6, [x21, #112]  
	ldp x9, x10, [x23, #112]  
	and x7, x7, x22  
	and x8, x8, x22  
	and x9, x9, x22  
	and x10, x10, x22  
	adcs x11, x3, x7  
	adcs x12, x4, x8  
	adcs x13, x5, x9  
	adcs x14, x6, x10  
	stp x11, x12, [x21, #96]  
	stp x13, x14, [x21, #112]  
	ldp x3, x4, [x21, #128]  
	ldp x7, x8, [x23, #128]  
	ldp x5, x6, [x21, #144]  
	ldp x9, x10, [x23, #144]  
	and x7, x7, x22  
	and x8, x8, x22  
	and x9, x9, x22  
	and x10, x10, x22  
	adcs x11, x3, x7  
	adcs x12, x4, x8  
	adcs x13, x5, x9  
	adcs x14, x6, x10  
	stp x11, x12, [x21, #128]  
	stp x13, x14, [x21, #144]  
	ldp x3, x4, [x21, #160]  
	ldp x7, x8, [x23, #160]  
	ldp x5, x6, [x21, #176]  
	ldp x9, x10, [x23, #176]  
	and x7, x7, x22  
	and x8, x8, x22  
	and x9, x9, x22  
	and x10, x10, x22  
	adcs x11, x3, x7  
	adcs x12, x4, x8  
	adcs x13, x5, x9  
	adcs x14, x6, x10  
	stp x11, x12, [x21, #160]  
	stp x13, x14, [x21, #176]  
	ldp x3, x4, [x21, #192]  
	ldp x7, x8, [x23, #192]  
	ldp x5, x6, [x21, #208]  
	ldp x9, x10, [x23, #208]  
	and x7, x7, x22  
	and x8, x8, x22  
	and x9, x9, x22  
	and x10, x10, x22  
	adcs x11, x3, x7  
	adcs x12, x4, x8  
	adcs x13, x5, x9  
	adcs x14, x6, x10  
	stp x11, x12, [x21, #192]  
	stp x13, x14, [x21, #208]  
	ldp x3, x4, [x21, #224]  
	ldp x7, x8, [x23, #224]  
	ldp x5, x6, [x21, #240]  
	ldp x9, x10, [x23, #240]  
	and x7, x7, x22  
	and x8, x8, x22  
	and x9, x9, x22  
	and x10, x10, x22  
	adcs x11, x3, x7  
	adcs x12, x4, x8  
	adcs x13, x5, x9  
	adcs x14, x6, x10  
	stp x11, x12, [x21, #224]  
	stp x13, x14, [x21, #240]  
	ldp x21, x22, [sp, #0]
	ldp x23, lr, [sp, #16]
	add sp, sp, #32
	ret

	/* A[x0] = A[x0] - B[x1] */
.global fp_sub2
fp_sub2: 
	mov x2, x1
	mov x1, x0
	/* A[x0] = A[x0] - B[x1] - C[x2] */
.global fp_sub3
fp_sub3: 
	sub sp, sp, #288
	stp lr, x19, [sp, #0]
	stp x20, x21, [sp, #16]
	/* Increment add/sub counter */
	adrp x3, fp_addsub_count@PAGE
	add x3, x3, fp_addsub_count@PAGEOFF
	ldr x4, [x3]
	add x4, x4, #1
	str x4, [x3]

	mov x19, x0
	mov x20, x1
	/* stack + 32 = -x2 */
	mov x1, x2
	add x0, sp, #32
	bl _minus_number
	mov x2, x0
	mov x0, x19
	mov x1, x20
	bl fp_add3
	ldp lr, x19, [sp, #0]
	ldp x20, x21, [sp, #16]
	add sp, sp, #288
	ret

	/* x0 = -x1 */
_minus_number: 
	sub sp, sp, #32
	stp x19, x20, [sp, #0]
	str x21, [sp, #16]
	adrp x20, uintbig_p@PAGE
	add x20, x20, uintbig_p@PAGEOFF
	mov x21, xzr  
	/* P-A */
	ldp x3, x4, [x1, #0]  
	ldp x7, x8, [x20, #0]  
	ldp x5, x6, [x1, #16]  
	ldp x9, x10, [x20, #16]  
	subs x11, x7, x3  
	orr x21, x21, x11  
	sbcs x12, x8, x4  
	orr x21, x21, x12  
	sbcs x13, x9, x5  
	orr x21, x21, x13  
	sbcs x14, x10, x6  
	orr x21, x21, x14  
	stp x11, x12, [x0, #0]  
	stp x13, x14, [x0, #16]  
	ldp x3, x4, [x1, #32]  
	ldp x7, x8, [x20, #32]  
	ldp x5, x6, [x1, #48]  
	ldp x9, x10, [x20, #48]  
	sbcs x11, x7, x3  
	orr x21, x21, x11  
	sbcs x12, x8, x4  
	orr x21, x21, x12  
	sbcs x13, x9, x5  
	orr x21, x21, x13  
	sbcs x14, x10, x6  
	orr x21, x21, x14  
	stp x11, x12, [x0, #32]  
	stp x13, x14, [x0, #48]  
	ldp x3, x4, [x1, #64]  
	ldp x7, x8, [x20, #64]  
	ldp x5, x6, [x1, #80]  
	ldp x9, x10, [x20, #80]  
	sbcs x11, x7, x3  
	orr x21, x21, x11  
	sbcs x12, x8, x4  
	orr x21, x21, x12  
	sbcs x13, x9, x5  
	orr x21, x21, x13  
	sbcs x14, x10, x6  
	orr x21, x21, x14  
	stp x11, x12, [x0, #64]  
	stp x13, x14, [x0, #80]  
	ldp x3, x4, [x1, #96]  
	ldp x7, x8, [x20, #96]  
	ldp x5, x6, [x1, #112]  
	ldp x9, x10, [x20, #112]  
	sbcs x11, x7, x3  
	orr x21, x21, x11  
	sbcs x12, x8, x4  
	orr x21, x21, x12  
	sbcs x13, x9, x5  
	orr x21, x21, x13  
	sbcs x14, x10, x6  
	orr x21, x21, x14  
	stp x11, x12, [x0, #96]  
	stp x13, x14, [x0, #112]  
	ldp x3, x4, [x1, #128]  
	ldp x7, x8, [x20, #128]  
	ldp x5, x6, [x1, #144]  
	ldp x9, x10, [x20, #144]  
	sbcs x11, x7, x3  
	orr x21, x21, x11  
	sbcs x12, x8, x4  
	orr x21, x21, x12  
	sbcs x13, x9, x5  
	orr x21, x21, x13  
	sbcs x14, x10, x6  
	orr x21, x21, x14  
	stp x11, x12, [x0, #128]  
	stp x13, x14, [x0, #144]  
	ldp x3, x4, [x1, #160]  
	ldp x7, x8, [x20, #160]  
	ldp x5, x6, [x1, #176]  
	ldp x9, x10, [x20, #176]  
	sbcs x11, x7, x3  
	orr x21, x21, x11  
	sbcs x12, x8, x4  
	orr x21, x21, x12  
	sbcs x13, x9, x5  
	orr x21, x21, x13  
	sbcs x14, x10, x6  
	orr x21, x21, x14  
	stp x11, x12, [x0, #160]  
	stp x13, x14, [x0, #176]  
	ldp x3, x4, [x1, #192]  
	ldp x7, x8, [x20, #192]  
	ldp x5, x6, [x1, #208]  
	ldp x9, x10, [x20, #208]  
	sbcs x11, x7, x3  
	orr x21, x21, x11  
	sbcs x12, x8, x4  
	orr x21, x21, x12  
	sbcs x13, x9, x5  
	orr x21, x21, x13  
	sbcs x14, x10, x6  
	orr x21, x21, x14  
	stp x11, x12, [x0, #192]  
	stp x13, x14, [x0, #208]  
	ldp x3, x4, [x1, #224]  
	ldp x7, x8, [x20, #224]  
	ldp x5, x6, [x1, #240]  
	ldp x9, x10, [x20, #240]  
	sbcs x11, x7, x3  
	orr x21, x21, x11  
	sbcs x12, x8, x4  
	orr x21, x21, x12  
	sbcs x13, x9, x5  
	orr x21, x21, x13  
	sbcs x14, x10, x6  
	orr x21, x21, x14  
	stp x11, x12, [x0, #224]  
	stp x13, x14, [x0, #240]  
	cmp x21, #0
	cset x21, eq
	lsl x21, x21, #63
	asr x21, x21, #63
	/* and the prime (if a was 0 then we and with 1, otherwise 0) */
	ldp x3, x4, [x0, #0]  
	ldp x7, x8, [x20, #0]  
	ldp x5, x6, [x0, #16]  
	ldp x9, x10, [x20, #16]  
	and x7, x7, x21  
	and x8, x8, x21  
	and x9, x9, x21  
	and x10, x10, x21  
	subs x11, x3, x7  
	sbcs x12, x4, x8  
	sbcs x13, x5, x9  
	sbcs x14, x6, x10  
	stp x11, x12, [x0, #0]  
	stp x13, x14, [x0, #16]  
	ldp x3, x4, [x0, #32]  
	ldp x7, x8, [x20, #32]  
	ldp x5, x6, [x0, #48]  
	ldp x9, x10, [x20, #48]  
	and x7, x7, x21  
	and x8, x8, x21  
	and x9, x9, x21  
	and x10, x10, x21  
	sbcs x11, x3, x7  
	sbcs x12, x4, x8  
	sbcs x13, x5, x9  
	sbcs x14, x6, x10  
	stp x11, x12, [x0, #32]  
	stp x13, x14, [x0, #48]  
	ldp x3, x4, [x0, #64]  
	ldp x7, x8, [x20, #64]  
	ldp x5, x6, [x0, #80]  
	ldp x9, x10, [x20, #80]  
	and x7, x7, x21  
	and x8, x8, x21  
	and x9, x9, x21  
	and x10, x10, x21  
	sbcs x11, x3, x7  
	sbcs x12, x4, x8  
	sbcs x13, x5, x9  
	sbcs x14, x6, x10  
	stp x11, x12, [x0, #64]  
	stp x13, x14, [x0, #80]  
	ldp x3, x4, [x0, #96]  
	ldp x7, x8, [x20, #96]  
	ldp x5, x6, [x0, #112]  
	ldp x9, x10, [x20, #112]  
	and x7, x7, x21  
	and x8, x8, x21  
	and x9, x9, x21  
	and x10, x10, x21  
	sbcs x11, x3, x7  
	sbcs x12, x4, x8  
	sbcs x13, x5, x9  
	sbcs x14, x6, x10  
	stp x11, x12, [x0, #96]  
	stp x13, x14, [x0, #112]  
	ldp x3, x4, [x0, #128]  
	ldp x7, x8, [x20, #128]  
	ldp x5, x6, [x0, #144]  
	ldp x9, x10, [x20, #144]  
	and x7, x7, x21  
	and x8, x8, x21  
	and x9, x9, x21  
	and x10, x10, x21  
	sbcs x11, x3, x7  
	sbcs x12, x4, x8  
	sbcs x13, x5, x9  
	sbcs x14, x6, x10  
	stp x11, x12, [x0, #128]  
	stp x13, x14, [x0, #144]  
	ldp x3, x4, [x0, #160]  
	ldp x7, x8, [x20, #160]  
	ldp x5, x6, [x0, #176]  
	ldp x9, x10, [x20, #176]  
	and x7, x7, x21  
	and x8, x8, x21  
	and x9, x9, x21  
	and x10, x10, x21  
	sbcs x11, x3, x7  
	sbcs x12, x4, x8  
	sbcs x13, x5, x9  
	sbcs x14, x6, x10  
	stp x11, x12, [x0, #160]  
	stp x13, x14, [x0, #176]  
	ldp x3, x4, [x0, #192]  
	ldp x7, x8, [x20, #192]  
	ldp x5, x6, [x0, #208]  
	ldp x9, x10, [x20, #208]  
	and x7, x7, x21  
	and x8, x8, x21  
	and x9, x9, x21  
	and x10, x10, x21  
	sbcs x11, x3, x7  
	sbcs x12, x4, x8  
	sbcs x13, x5, x9  
	sbcs x14, x6, x10  
	stp x11, x12, [x0, #192]  
	stp x13, x14, [x0, #208]  
	ldp x3, x4, [x0, #224]  
	ldp x7, x8, [x20, #224]  
	ldp x5, x6, [x0, #240]  
	ldp x9, x10, [x20, #240]  
	and x7, x7, x21  
	and x8, x8, x21  
	and x9, x9, x21  
	and x10, x10, x21  
	sbcs x11, x3, x7  
	sbcs x12, x4, x8  
	sbcs x13, x5, x9  
	sbcs x14, x6, x10  
	stp x11, x12, [x0, #224]  
	stp x13, x14, [x0, #240]  
	ldp x19, x20, [sp, #0]
	ldr x21, [sp, #16]
	add sp, sp, #32
	ret

	/* x0 = x0^2, straight to fp_sq2 */
.global fp_sq1
fp_sq1: 
	mov x1, x0
	/* x0 = x1^2 mod p */
.global fp_sq2
fp_sq2: 
	/* Increment sq counter */
	adrp x3, fp_sq_count@PAGE
	add x3, x3, fp_sq_count@PAGEOFF
	ldr x4, [x3]
	add x4, x4, #1
	str x4, [x3]

	mov x2, x1
	b fp_mul3
