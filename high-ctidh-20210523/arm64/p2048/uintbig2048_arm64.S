/* This file is automatically generated by autogen_uintbig1000.py */
/* DO NOT EDIT! */
#include "../../uintbig_namespace.h" 
/* This file contains functions for 2048-bit unsigned integers */
.global uintbig_1
uintbig_1: 
	.quad 1, 0, 0, 0
	.quad 0, 0, 0, 0
	.quad 0, 0, 0, 0
	.quad 0, 0, 0, 0
	.quad 0, 0, 0, 0
	.quad 0, 0, 0, 0
	.quad 0, 0, 0, 0
	.quad 0, 0, 0, 0

.global uintbig_p
uintbig_p: 
    .quad 0x7790d615ea034943, 0xdc703f0cd8c4d918, 0x95a98036c813c788, 0xe111b0d22ab8ecaa
    .quad 0x6478407d7a9a56ee, 0xa7bec86fabaf787f, 0x44454e851cf305ab, 0x44084e1a73c76cb2
    .quad 0x2842bbe4dbacc65e, 0x58e89497ef35bbb9, 0x9796620b3ad8a5d4, 0x5377d53e856cc9a3
    .quad 0x7c4cb419996f45e7, 0x88c691b2d452a8ac, 0x0da1783672767abb, 0x9844e5c09baf59ec
    .quad 0xe33586d1208a1017, 0x7d84f102b5fde2ea, 0x30d2edfe50198c64, 0x095ac8a9f3ce2b0c
    .quad 0x93e73abd17e3aa46, 0xc680497933375253, 0x6557ebe96d91aedd, 0x4dd6024bf2f8feab
    .quad 0xb8523d6a302abf28, 0x33a8779a1ec8b8c2, 0x584eb12932f72abb, 0xdbd1fc2133770253
    .quad 0xddffdcf1aee53f12, 0x4d8854e8b3e19c53, 0x97fefc90e8196ed9, 0x438efcab10254c64

.global uintbig_four_sqrt_p
uintbig_four_sqrt_p: 
    .quad 0x713138678208efe5, 0x99b865c7a60b9d15, 0xcb9d5709a6d520ec, 0x8ba25da98b117e65
    .quad 0xb53f431fbbbc1b57, 0xa182b3a2a32514ca, 0xbd8509d767f7a86c, 0x50d56ce140ad8057
    .quad 0xf15c586b92287b69, 0x89a81119287fc51f, 0x5721ecd10a5f822a, 0xbc1272d7e7a1d02c
    .quad 0x8ae8830a4b03c676, 0xb4c29be61adeea3a, 0xd31c1b050625e30b, 0x0e0aa7f8149f0a5a
    .quad 2, 0, 0, 0
    .quad 0, 0, 0, 0
    .quad 0, 0, 0, 0
    .quad 0, 0, 0, 0

.text
.align 4

/* A[x0][0] = x1, rest 0 */
.global uintbig_set
uintbig_set: 
	stp x1, xzr, [x0, #0]
	stp xzr, xzr, [x0, #16]
	stp xzr, xzr, [x0, #32]
	stp xzr, xzr, [x0, #48]
	stp xzr, xzr, [x0, #64]
	stp xzr, xzr, [x0, #80]
	stp xzr, xzr, [x0, #96]
	stp xzr, xzr, [x0, #112]
	stp xzr, xzr, [x0, #128]
	stp xzr, xzr, [x0, #144]
	stp xzr, xzr, [x0, #160]
	stp xzr, xzr, [x0, #176]
	stp xzr, xzr, [x0, #192]
	stp xzr, xzr, [x0, #208]
	stp xzr, xzr, [x0, #224]
	stp xzr, xzr, [x0, #240]
	ret

/* Operation: x0 = x0[x1] == 1 */
/* Checks if bit at position x1 is set */
.global uintbig_bit
uintbig_bit: 
	and x2, x1, #0x3F   // x2 = x0 % 64 using bitwise AND
	lsr x1, x1, #6      // x1 = x1 / 64 by right-shifting
	lsl x1, x1, #3      // 8 * (x1 / 64) 
	ldr x3, [x0, x1]    // Load the limb at: x0 + 8 * (k / 64) 
	lsr x3, x3, x2  // Right shift by x0%64 to bring the bit of interest to the least significant position
	and x0, x3, #1  // Check if the least significant bit is set
	ret

/* Operation: A[x0] = B[x1] + C[x2] and x0 = carry */
.global uintbig_add3
uintbig_add3: 

/* load batch 0 */
	ldp x3, x4, [x1, #0]
	ldp x7, x8, [x2, #0]
	ldp x5, x6, [x1, #16]
	ldp x9, x10, [x2, #16]
	adds x11, x3, x7
	adcs x12, x4, x8
	adcs x13, x5, x9
	adcs x14, x6, x10
	stp x11, x12, [x0, #0]
	stp x13, x14, [x0, #16]

/* load batch 1 */
	ldp x3, x4, [x1, #32]
	ldp x7, x8, [x2, #32]
	ldp x5, x6, [x1, #48]
	ldp x9, x10, [x2, #48]
	adcs x11, x3, x7
	adcs x12, x4, x8
	adcs x13, x5, x9
	adcs x14, x6, x10
	stp x11, x12, [x0, #32]
	stp x13, x14, [x0, #48]

/* load batch 2 */
	ldp x3, x4, [x1, #64]
	ldp x7, x8, [x2, #64]
	ldp x5, x6, [x1, #80]
	ldp x9, x10, [x2, #80]
	adcs x11, x3, x7
	adcs x12, x4, x8
	adcs x13, x5, x9
	adcs x14, x6, x10
	stp x11, x12, [x0, #64]
	stp x13, x14, [x0, #80]

/* load batch 3 */
	ldp x3, x4, [x1, #96]
	ldp x7, x8, [x2, #96]
	ldp x5, x6, [x1, #112]
	ldp x9, x10, [x2, #112]
	adcs x11, x3, x7
	adcs x12, x4, x8
	adcs x13, x5, x9
	adcs x14, x6, x10
	stp x11, x12, [x0, #96]
	stp x13, x14, [x0, #112]

/* load batch 4 */
	ldp x3, x4, [x1, #128]
	ldp x7, x8, [x2, #128]
	ldp x5, x6, [x1, #144]
	ldp x9, x10, [x2, #144]
	adcs x11, x3, x7
	adcs x12, x4, x8
	adcs x13, x5, x9
	adcs x14, x6, x10
	stp x11, x12, [x0, #128]
	stp x13, x14, [x0, #144]

/* load batch 5 */
	ldp x3, x4, [x1, #160]
	ldp x7, x8, [x2, #160]
	ldp x5, x6, [x1, #176]
	ldp x9, x10, [x2, #176]
	adcs x11, x3, x7
	adcs x12, x4, x8
	adcs x13, x5, x9
	adcs x14, x6, x10
	stp x11, x12, [x0, #160]
	stp x13, x14, [x0, #176]

/* load batch 6 */
	ldp x3, x4, [x1, #192]
	ldp x7, x8, [x2, #192]
	ldp x5, x6, [x1, #208]
	ldp x9, x10, [x2, #208]
	adcs x11, x3, x7
	adcs x12, x4, x8
	adcs x13, x5, x9
	adcs x14, x6, x10
	stp x11, x12, [x0, #192]
	stp x13, x14, [x0, #208]

/* load batch 7 */
	ldp x3, x4, [x1, #224]
	ldp x7, x8, [x2, #224]
	ldp x5, x6, [x1, #240]
	ldp x9, x10, [x2, #240]
	adcs x11, x3, x7
	adcs x12, x4, x8
	adcs x13, x5, x9
	adcs x14, x6, x10
	stp x11, x12, [x0, #224]
	stp x13, x14, [x0, #240]
/* Final Carry into x0 */
	adc x0, xzr, xzr
	ret

/* Operation: A[x0] = B[x1] - C[x2] and x0 = borrow */
.global uintbig_sub3
uintbig_sub3: 

/* load batch 0 */
	ldp x3, x4, [x1, #0]
	ldp x7, x8, [x2, #0]
	ldp x5, x6, [x1, #16]
	ldp x9, x10, [x2, #16]
	subs x11, x3, x7
	sbcs x12, x4, x8
	sbcs x13, x5, x9
	sbcs x14, x6, x10
	stp x11, x12, [x0, #0]
	stp x13, x14, [x0, #16]

/* load batch 1 */
	ldp x3, x4, [x1, #32]
	ldp x7, x8, [x2, #32]
	ldp x5, x6, [x1, #48]
	ldp x9, x10, [x2, #48]
	sbcs x11, x3, x7
	sbcs x12, x4, x8
	sbcs x13, x5, x9
	sbcs x14, x6, x10
	stp x11, x12, [x0, #32]
	stp x13, x14, [x0, #48]

/* load batch 2 */
	ldp x3, x4, [x1, #64]
	ldp x7, x8, [x2, #64]
	ldp x5, x6, [x1, #80]
	ldp x9, x10, [x2, #80]
	sbcs x11, x3, x7
	sbcs x12, x4, x8
	sbcs x13, x5, x9
	sbcs x14, x6, x10
	stp x11, x12, [x0, #64]
	stp x13, x14, [x0, #80]

/* load batch 3 */
	ldp x3, x4, [x1, #96]
	ldp x7, x8, [x2, #96]
	ldp x5, x6, [x1, #112]
	ldp x9, x10, [x2, #112]
	sbcs x11, x3, x7
	sbcs x12, x4, x8
	sbcs x13, x5, x9
	sbcs x14, x6, x10
	stp x11, x12, [x0, #96]
	stp x13, x14, [x0, #112]

/* load batch 4 */
	ldp x3, x4, [x1, #128]
	ldp x7, x8, [x2, #128]
	ldp x5, x6, [x1, #144]
	ldp x9, x10, [x2, #144]
	sbcs x11, x3, x7
	sbcs x12, x4, x8
	sbcs x13, x5, x9
	sbcs x14, x6, x10
	stp x11, x12, [x0, #128]
	stp x13, x14, [x0, #144]

/* load batch 5 */
	ldp x3, x4, [x1, #160]
	ldp x7, x8, [x2, #160]
	ldp x5, x6, [x1, #176]
	ldp x9, x10, [x2, #176]
	sbcs x11, x3, x7
	sbcs x12, x4, x8
	sbcs x13, x5, x9
	sbcs x14, x6, x10
	stp x11, x12, [x0, #160]
	stp x13, x14, [x0, #176]

/* load batch 6 */
	ldp x3, x4, [x1, #192]
	ldp x7, x8, [x2, #192]
	ldp x5, x6, [x1, #208]
	ldp x9, x10, [x2, #208]
	sbcs x11, x3, x7
	sbcs x12, x4, x8
	sbcs x13, x5, x9
	sbcs x14, x6, x10
	stp x11, x12, [x0, #192]
	stp x13, x14, [x0, #208]

/* load batch 7 */
	ldp x3, x4, [x1, #224]
	ldp x7, x8, [x2, #224]
	ldp x5, x6, [x1, #240]
	ldp x9, x10, [x2, #240]
	sbcs x11, x3, x7
	sbcs x12, x4, x8
	sbcs x13, x5, x9
	sbcs x14, x6, x10
	stp x11, x12, [x0, #224]
	stp x13, x14, [x0, #240]
/* Final Carry into x0 */
	sbc x0, xzr, xzr
	ret

/* Operation: A[x0] = B[x1] * C[x2] and C = direct value 64 bit not address */
.global uintbig_mul3_64
uintbig_mul3_64: 
/* 0 Limb */
	ldp x3, x4, [x1, #0]
	mul x5, x3, x2 // low mul
	umulh x6, x3, x2 // high mul
	str x5, [x0, #0]

/* 1 Limb */
	mul x5, x4, x2 // low mul
	adds x5, x5, x6 // add past higher mul
	str x5, [x0, #8]
	umulh x6, x4, x2 // high mul

/* 2 Limb */
	ldp x3, x4, [x1, #16]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #16]
	umulh x6, x3, x2 // high mul
/* 3 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #24]
	umulh x6, x4, x2 // high mul 

/* 4 Limb */
	ldp x3, x4, [x1, #32]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #32]
	umulh x6, x3, x2 // high mul
/* 5 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #40]
	umulh x6, x4, x2 // high mul 

/* 6 Limb */
	ldp x3, x4, [x1, #48]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #48]
	umulh x6, x3, x2 // high mul
/* 7 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #56]
	umulh x6, x4, x2 // high mul 

/* 8 Limb */
	ldp x3, x4, [x1, #64]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #64]
	umulh x6, x3, x2 // high mul
/* 9 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #72]
	umulh x6, x4, x2 // high mul 

/* 10 Limb */
	ldp x3, x4, [x1, #80]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #80]
	umulh x6, x3, x2 // high mul
/* 11 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #88]
	umulh x6, x4, x2 // high mul 

/* 12 Limb */
	ldp x3, x4, [x1, #96]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #96]
	umulh x6, x3, x2 // high mul
/* 13 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #104]
	umulh x6, x4, x2 // high mul 

/* 14 Limb */
	ldp x3, x4, [x1, #112]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #112]
	umulh x6, x3, x2 // high mul
/* 15 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #120]
	umulh x6, x4, x2 // high mul 

/* 16 Limb */
	ldp x3, x4, [x1, #128]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #128]
	umulh x6, x3, x2 // high mul
/* 17 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #136]
	umulh x6, x4, x2 // high mul 

/* 18 Limb */
	ldp x3, x4, [x1, #144]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #144]
	umulh x6, x3, x2 // high mul
/* 19 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #152]
	umulh x6, x4, x2 // high mul 

/* 20 Limb */
	ldp x3, x4, [x1, #160]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #160]
	umulh x6, x3, x2 // high mul
/* 21 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #168]
	umulh x6, x4, x2 // high mul 

/* 22 Limb */
	ldp x3, x4, [x1, #176]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #176]
	umulh x6, x3, x2 // high mul
/* 23 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #184]
	umulh x6, x4, x2 // high mul 

/* 24 Limb */
	ldp x3, x4, [x1, #192]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #192]
	umulh x6, x3, x2 // high mul
/* 25 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #200]
	umulh x6, x4, x2 // high mul 

/* 26 Limb */
	ldp x3, x4, [x1, #208]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #208]
	umulh x6, x3, x2 // high mul
/* 27 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #216]
	umulh x6, x4, x2 // high mul 

/* 28 Limb */
	ldp x3, x4, [x1, #224]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #224]
	umulh x6, x3, x2 // high mul
/* 29 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #232]
	umulh x6, x4, x2 // high mul 

/* 30 Limb */
	ldp x3, x4, [x1, #240]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #240]
	umulh x6, x3, x2 // high mul
/* 31 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #248]
	umulh x6, x4, x2 // high mul 

	ret

/* Operation: A[x0] = B[x1] * C[x2] and C = direct value 64 bit not address
 results in 9 words */
.global uintbig_mul3_64_full
uintbig_mul3_64_full: 
/* 0 Limb */
	ldp x3, x4, [x1, #0]
	mul x5, x3, x2 // low mul
	umulh x6, x3, x2 // high mul
	str x5, [x0, #0]

/* 1 Limb */
	mul x5, x4, x2 // low mul
	adds x5, x5, x6 // add past higher mul
	str x5, [x0, #8]
	umulh x6, x4, x2 // high mul

/* 2 Limb */
	ldp x3, x4, [x1, #16]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #16]
	umulh x6, x3, x2 // high mul
/* 3 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #24]
	umulh x6, x4, x2 // high mul 

/* 4 Limb */
	ldp x3, x4, [x1, #32]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #32]
	umulh x6, x3, x2 // high mul
/* 5 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #40]
	umulh x6, x4, x2 // high mul 

/* 6 Limb */
	ldp x3, x4, [x1, #48]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #48]
	umulh x6, x3, x2 // high mul
/* 7 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #56]
	umulh x6, x4, x2 // high mul 

/* 8 Limb */
	ldp x3, x4, [x1, #64]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #64]
	umulh x6, x3, x2 // high mul
/* 9 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #72]
	umulh x6, x4, x2 // high mul 

/* 10 Limb */
	ldp x3, x4, [x1, #80]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #80]
	umulh x6, x3, x2 // high mul
/* 11 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #88]
	umulh x6, x4, x2 // high mul 

/* 12 Limb */
	ldp x3, x4, [x1, #96]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #96]
	umulh x6, x3, x2 // high mul
/* 13 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #104]
	umulh x6, x4, x2 // high mul 

/* 14 Limb */
	ldp x3, x4, [x1, #112]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #112]
	umulh x6, x3, x2 // high mul
/* 15 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #120]
	umulh x6, x4, x2 // high mul 

/* 16 Limb */
	ldp x3, x4, [x1, #128]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #128]
	umulh x6, x3, x2 // high mul
/* 17 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #136]
	umulh x6, x4, x2 // high mul 

/* 18 Limb */
	ldp x3, x4, [x1, #144]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #144]
	umulh x6, x3, x2 // high mul
/* 19 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #152]
	umulh x6, x4, x2 // high mul 

/* 20 Limb */
	ldp x3, x4, [x1, #160]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #160]
	umulh x6, x3, x2 // high mul
/* 21 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #168]
	umulh x6, x4, x2 // high mul 

/* 22 Limb */
	ldp x3, x4, [x1, #176]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #176]
	umulh x6, x3, x2 // high mul
/* 23 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #184]
	umulh x6, x4, x2 // high mul 

/* 24 Limb */
	ldp x3, x4, [x1, #192]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #192]
	umulh x6, x3, x2 // high mul
/* 25 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #200]
	umulh x6, x4, x2 // high mul 

/* 26 Limb */
	ldp x3, x4, [x1, #208]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #208]
	umulh x6, x3, x2 // high mul
/* 27 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #216]
	umulh x6, x4, x2 // high mul 

/* 28 Limb */
	ldp x3, x4, [x1, #224]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #224]
	umulh x6, x3, x2 // high mul
/* 29 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #232]
	umulh x6, x4, x2 // high mul 

/* 30 Limb */
	ldp x3, x4, [x1, #240]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #240]
	umulh x6, x3, x2 // high mul
/* 31 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #248]
	umulh x6, x4, x2 // high mul 

	adc x6, x6, xzr
	str x6, [x0, #256]
	ret

