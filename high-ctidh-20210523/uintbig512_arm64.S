/* DO NOT EDIT! generated by autogen */

#include "uintbig_namespace.h" 
.data

.global _uintbig_1
_uintbig_1: 
	.quad 1, 0, 0, 0
	.quad 0, 0, 0, 0

.global _uintbig_p
_uintbig_p: 
	.quad 0x1b81b90533c6c87b, 0xc2721bf457aca835, 0x516730cc1f0b4f25, 0xa7aac6c567f35507
	.quad 0x5afbfcc69322c9cd, 0xb42d083aedc88c42, 0xfc8ab0d15e3e4c4a, 0x65b48e8f740f89bf

.global _uintbig_four_sqrt_p
_uintbig_four_sqrt_p: 
	.quad 0x17895e71e1a20b3f, 0x38d0cd95f8636a56, 0x142b9541e59682cd, 0x856f1399d91d6592
	.quad 2, 0, 0, 0

.text
.align 4

/* A[x0][0] = x1, rest 0 */
.global _uintbig_set
_uintbig_set: 
\str x1, [x0]
mov x2, 0
stp x1, x2, [x0, #0]	stp x2, x2, [x0, #16]	stp x2, x2, [x0, #32]	stp x2, x2, [x0, #48]	et

/* Operation: x0 = x0[x1] == 1 */
/* Checks if bit at position x1 is set */
.global _uintbig_bit
_uintbig_bit: 
	and x2, x1, #0x3F   // x2 = x0 % 64 using bitwise AND
	lsr x1, x1, #6      // x1 = x1 / 64 by right-shifting
	lsl x1, x1, #3      // 8 * (x1 / 64)	ldr x3, [x0, x1]    // Load the limb at: x0 + 8 * (k / 64) 
	lsr x3, x3, x2  // Right shift by x0%64 to bring the bit of interest to the least significant position
	and x0, x3, #1  // Check if the least significant bit is set
	ret

/* Operation: A[x0] = B[x1] + C[x2] and x0 = carry */
.global _uintbig_add3
_uintbig_add3: 
	sub sp, sp, #16
	stp x19, x20, [sp, #0]
	ldp x3, x4, [x1, #0]
	ldp x11, x12, [x2, #0]
	ldp x5, x6, [x1, #16]
	ldp x13, x14, [x2, #16]
	ldp x7, x8, [x1, #32]
	ldp x15, x16, [x2, #32]
	ldp x9, x10, [x1, #48]
	ldp x17, x19, [x2, #48]
	adds x3, x3, x11
	adcs x4, x4, x12
	adcs x5, x5, x13
	adcs x6, x6, x14
	adcs x7, x7, x15
	adcs x8, x8, x16
	adcs x9, x9, x17
	adcs x10, x10, x19
	stp x3, x4, [x0, #0]
	stp x5, x6, [x0, #16]
	stp x7, x8, [x0, #32]
	stp x9, x10, [x0, #48]
/* Carry into x11 */
	adc x0, xzr, xzr
	add sp, sp, #16
	ldp x19, x20, [sp, #0]
	ret

/* Operation: A[x0] = B[x1] - C[x2] and x0 = borrow */
.global _uintbig_sub3
_uintbig_sub3: 
	sub sp, sp, #16
	stp x19, x20, [sp, #0]
	ldp x3, x4, [x1, #0]
	ldp x11, x12, [x2, #0]
	ldp x5, x6, [x1, #16]
	ldp x13, x14, [x2, #16]
	ldp x7, x8, [x1, #32]
	ldp x15, x16, [x2, #32]
	ldp x9, x10, [x1, #48]
	ldp x17, x19, [x2, #48]
	subs x3, x3, x11
	sbcs x4, x4, x12
	sbcs x5, x5, x13
	sbcs x6, x6, x14
	sbcs x7, x7, x15
	sbcs x8, x8, x16
	sbcs x9, x9, x17
	sbcs x10, x10, x19
	stp x3, x4, [x0, #0]
	stp x5, x6, [x0, #16]
	stp x7, x8, [x0, #32]
	stp x9, x10, [x0, #48]
/* Carry into x11 */
	sbc x0, xzr, xzr
	add sp, sp, #16
	ldp x19, x20, [sp, #0]
	ret

/* Operation: A[x0] = B[x1] * C[x2] and C = direct value 64 bit not address */
.global _uintbig_mul3_64
_uintbig_mul3_64: 
/* 0 Limb */
	ldp x3, x4, [x1, #0]
	mul x5, x3, x2 // low mul
	umulh x6, x3, x2 // high mul
	str x5, [x0, #0]

/* 1 Limb */
	mul x5, x4, x2 // low mul
	adds x5, x5, x6 // add past higher mul
	str x5, [x0, #8]
	umulh x6, x4, x2 // high mul

/* 2 Limb */
	ldp x3, x4, [x1, #16]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #16]
	umulh x6, x3, x2 // high mul
/* 3 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #24]
	umulh x6, x4, x2 // high mul 

/* 4 Limb */
	ldp x3, x4, [x1, #32]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #32]
	umulh x6, x3, x2 // high mul
/* 5 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #40]
	umulh x6, x4, x2 // high mul 

/* 6 Limb */
	ldp x3, x4, [x1, #48]
	mul x5, x3, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #48]
	umulh x6, x3, x2 // high mul
/* 7 Limb */
	mul x5, x4, x2 // low mul
	adcs x5, x5, x6 // add past higher mul
	str x5, [x0, #56]
	umulh x6, x4, x2 // high mul 

	ret

